{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "#Statistics Basic Theoretical Answers:-\n",
        "---\n",
        "---\n",
        "###1. What is statistics, and why is it important?\n",
        "Statistics is the study of collecting, organizing, analyzing, interpreting, and presenting data.                             \n",
        "Importance: It helps in decision-making, identifying trends, making predictions, and solving real-world problems in fields like business, healthcare, and AI/ML.\n",
        "\n",
        "---\n",
        "###2. What are the two main types of statistics?\n",
        "Descriptive Statistics: Summarizes and presents data. (e.g., mean, median, mode)                                                             \n",
        "Inferential Statistics: Makes predictions or generalizations about a population based on sample data. (e.g., hypothesis testing)\n",
        "\n",
        "---\n",
        "###3. What are descriptive statistics?\n",
        "Techniques that summarize data using measures like mean, median, mode, range, variance, and standard deviation.\n",
        "\n",
        "---\n",
        "###4. What is inferential statistics?\n",
        "It involves drawing conclusions about a population using sample data through hypothesis testing, confidence intervals, and regression analysis.\n",
        "\n",
        "---\n",
        "###5. What is sampling in statistics?\n",
        "Sampling is the process of selecting a subset of individuals from a population to estimate characteristics of the whole population.\n",
        "\n",
        "---\n",
        "###6. What are the different types of sampling methods?\n",
        "Probability Sampling (Random methods)                          \n",
        "Simple Random Sampling                             \n",
        "Stratified Sampling                       \n",
        "Cluster Sampling                                             \n",
        "Systematic Sampling\n",
        "\n",
        "Non-Probability Sampling (Non-random methods)                            \n",
        "Convenience Sampling                                \n",
        "Judgmental Sampling                                   \n",
        "Snowball Sampling                                    \n",
        "Quota Sampling                               \n",
        "\n",
        "---\n",
        "###7. What is the difference between random and non-random sampling?\n",
        "Random Sampling: Each member has an equal chance of selection (reduces bias).                           \n",
        "Non-Random Sampling: Selection is based on convenience or judgment (may introduce bias).\n",
        "\n",
        "---\n",
        "###8. Define and give examples of qualitative and quantitative data.\n",
        "Qualitative (Categorical) Data: Non-numeric, represents categories. (e.g., Gender, Colors, Types of Cars)                                  \n",
        "Quantitative (Numerical) Data: Numeric values, can be measured. (e.g., Height, Age, Temperature)\n",
        "\n",
        "---\n",
        "###9. What are the different types of data in statistics?\n",
        "Categorical Data: Nominal, Ordinal                                  \n",
        "Numerical Data: Discrete, Continuous   \n",
        "\n",
        "---\n",
        "###10. Explain nominal, ordinal, interval, and ratio levels of measurement.\n",
        "Nominal: Categories without order (e.g., Colors, Gender)            \n",
        "Ordinal: Ordered categories without exact differences (e.g., Ratings: Good, Better, Best)                                            \n",
        "Interval: Ordered, equal differences, but no true zero (e.g., Temperature in Celsius)                                           \n",
        "Ratio: Ordered, equal differences, true zero exists (e.g., Weight, Height)\n",
        "\n",
        "---\n",
        "###11. What is the measure of central tendency?                         \n",
        "A statistic that identifies the center of a dataset (Mean, Median, Mode).\n",
        "\n",
        "---\n",
        "###12. Define mean, median, and mode.\n",
        "Mean: Average of all values.                                     \n",
        "Median: Middle value in an ordered dataset.                              \n",
        "Mode: Most frequently occurring value.  \n",
        "\n",
        "---\n",
        "###13. What is the significance of the measure of central tendency?\n",
        "It helps summarize large datasets with a single value and provides insights into data distribution.\n",
        "\n",
        "---\n",
        "###14. What is variance, and how is it calculated?\n",
        "Variance measures how far each data point is from the mean.\n",
        "\n",
        "Formula:\n",
        "𝜎\n",
        "2\n",
        "=\n",
        "∑\n",
        "(\n",
        "𝑥\n",
        "𝑖\n",
        "−\n",
        "𝑥\n",
        "ˉ\n",
        ")\n",
        "2\n",
        "𝑛\n",
        "σ\n",
        "2\n",
        " =\n",
        "n\n",
        "∑(x\n",
        "i\n",
        "​\n",
        " −\n",
        "x\n",
        "ˉ\n",
        " )\n",
        "2\n",
        "\n",
        "\n",
        "where 𝑥𝑖 is each data point, x is the mean, and 𝑛 is the total number of data points.\n",
        "\n",
        "---\n",
        "###15. What is standard deviation, and why is it important?\n",
        "Standard deviation (\n",
        "𝜎\n",
        "σ) is the square root of variance and shows data spread.\n",
        "Importance: Helps understand variability in data.\n",
        "\n",
        "---\n",
        "###16. Define and explain the term range in statistics.\n",
        "Range = Maximum value - Minimum value                            \n",
        "It shows the spread of data.\n",
        "\n",
        "---\n",
        "###17. What is the difference between variance and standard deviation?\n",
        "Variance: Measures spread in squared units.                              \n",
        "Standard Deviation: Square root of variance, measured in the same units as data.\n",
        "\n",
        "---\n",
        "###18. What is skewness in a dataset?                                  \n",
        "Measures the asymmetry of data distribution.                               \n",
        "Types:\n",
        "Positive Skew (Right-skewed): Tail on the right.                         \n",
        "Negative Skew (Left-skewed): Tail on the left.\n",
        "\n",
        "---\n",
        "###19. What does it mean if a dataset is positively or negatively skewed?\n",
        "Positively Skewed: Mean > Median > Mode                    \n",
        "Negatively Skewed: Mean < Median < Mode\n",
        "\n",
        "---\n",
        "###20. Define and explain kurtosis.\n",
        "Kurtosis measures whether data has heavy or light tails.                  \n",
        "Types:                                            \n",
        "Leptokurtic: Heavy tails (more outliers).                      \n",
        "Mesokurtic: Normal distribution.                                   \n",
        "Platykurtic: Light tails (fewer outliers).\n",
        "\n",
        "---\n",
        "###21. What is the purpose of covariance?        \n",
        "Measures how two variables change together.                            \n",
        "Positive covariance: Variables move in the same direction.                  \n",
        "Negative covariance: Variables move in opposite directions.\n",
        "\n",
        "---\n",
        "###22. What does correlation measure in statistics?\n",
        "Measures the strength and direction of a relationship between two variables.                                                     \n",
        "Ranges from -1 (strong negative) to +1 (strong positive).\n",
        "\n",
        "---\n",
        "###23. What is the difference between covariance and correlation?\n",
        "Covariance: Measures how two variables vary together (units dependent).    \n",
        "Correlation: Standardized measure (unit-free, between -1 and 1).\n",
        "\n",
        "---\n",
        "###24. What are some real-world applications of statistics?\n",
        "Business: Market analysis, sales forecasting.              \n",
        "Healthcare: Disease prediction, clinical trials.                        \n",
        "Finance: Risk assessment, stock market analysis.                     \n",
        "AI/ML: Data preprocessing, model evaluation.\n",
        "\n",
        "---\n",
        "---\n",
        "Practical Answers:-\n",
        "---\n",
        "---\n",
        "---\n",
        "###1. Calculate the Mean, Median, and Mode of a Dataset"
      ],
      "metadata": {
        "id": "P6_Lx6nWAAqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "data = [10, 20, 30, 40, 50, 50, 60, 70, 80, 90]\n",
        "\n",
        "mean = np.mean(data)\n",
        "median = np.median(data)\n",
        "mode = stats.mode(data)\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Median: {median}\")\n",
        "print(f\"Mode: {mode.mode[0]}\")"
      ],
      "metadata": {
        "id": "nR4W8l69gwqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Write a Python program to compute the variance and standard deviation of a dataset"
      ],
      "metadata": {
        "id": "8xyytHTTg0dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample dataset\n",
        "data = [10, 12, 23, 23, 16, 23, 21, 16, 19, 12]\n",
        "\n",
        "# Variance\n",
        "variance = np.var(data, ddof=0)  # Population variance\n",
        "std_dev = np.std(data, ddof=0)  # Population standard deviation\n",
        "\n",
        "print(\"Variance:\", variance)\n",
        "print(\"Standard Deviation:\", std_dev)"
      ],
      "metadata": {
        "id": "wk-KRBDUg9oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Create a dataset and classify it into nominal, ordinal, interval, and ratio types"
      ],
      "metadata": {
        "id": "DsnR025ohAej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating the dataset\n",
        "data = pd.DataFrame({\n",
        "    'Student_ID': range(1, 11),  # Nominal\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma', 'Frank', 'Grace', 'Harry', 'Ivy', 'Jack'],  # Nominal\n",
        "    'Gender': ['Female', 'Male', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male'],  # Nominal\n",
        "    'Education_Level': ['High School', \"Bachelor's\", \"Master's\", 'High School', \"Bachelor's\", 'PhD', \"Master's\", 'High School', \"Bachelor's\", 'PhD'],  # Ordinal\n",
        "    'Age': [16, 21, 24, 17, 22, 28, 25, 18, 23, 30],  # Ratio\n",
        "    'Temperature': [36.5, 37.2, 38.0, 35.8, 37.5, 36.7, 37.0, 36.9, 37.1, 38.2],  # Interval\n",
        "    'Height_cm': [160, 175, 168, 172, 165, 178, 162, 170, 163, 180],  # Ratio\n",
        "    'Weight_kg': [50, 68, 70, 65, 55, 80, 58, 75, 54, 85],  # Ratio\n",
        "    'Exam_Score': [85, 78, 90, 82, 88, 95, 92, 76, 89, 97]  # Ratio\n",
        "})\n",
        "\n",
        "# Categorizing columns based on data type\n",
        "data_types = {\n",
        "    'Nominal': ['Student_ID', 'Name', 'Gender'],\n",
        "    'Ordinal': ['Education_Level'],\n",
        "    'Interval': ['Temperature'],\n",
        "    'Ratio': ['Age', 'Height_cm', 'Weight_kg', 'Exam_Score']\n",
        "}\n",
        "\n",
        "# Display dataset\n",
        "print(\"Dataset:\\n\", data)\n",
        "print(\"\\nCategorization of Variables:\\n\", data_types)"
      ],
      "metadata": {
        "id": "xVl4deG2hEkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Implement sampling techniques like random sampling and stratified sampling"
      ],
      "metadata": {
        "id": "4-fnRyIhjI6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Creating a sample dataset\n",
        "data = pd.DataFrame({\n",
        "    'ID': range(1, 101),\n",
        "    'Category': np.random.choice(['A', 'B', 'C'], 100),\n",
        "    'Value': np.random.randint(10, 100, 100)\n",
        "})\n",
        "\n",
        "# Simple Random Sampling\n",
        "random_sample = data.sample(n=10, random_state=42)\n",
        "\n",
        "# Stratified Sampling\n",
        "stratified_sample = data.groupby('Category', group_keys=False).apply(lambda x: x.sample(3))\n",
        "\n",
        "print(\"Random Sample:\\n\", random_sample)\n",
        "print(\"\\nStratified Sample:\\n\", stratified_sample)"
      ],
      "metadata": {
        "id": "Wo76eAX1jNo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Write a Python function to calculate the range of a dataset"
      ],
      "metadata": {
        "id": "_qmWMVidlIqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_range(data):\n",
        "    return max(data) - min(data)\n",
        "\n",
        "# Example\n",
        "data = [4, 10, 15, 23, 30]\n",
        "print(\"Range:\", calculate_range(data))"
      ],
      "metadata": {
        "id": "o3LqA4TvlZXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Create a dataset and plot its histogram to visualize skewness"
      ],
      "metadata": {
        "id": "QAiSoRV4lchL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample skewed dataset\n",
        "data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "plt.hist(data, bins=30, edgecolor='black')\n",
        "plt.title(\"Histogram of Dataset\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FLPstOWslfG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. Calculate skewness and kurtosis of a dataset using Python libraries"
      ],
      "metadata": {
        "id": "MZlm2MKElg2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Sample dataset\n",
        "data = np.random.normal(loc=50, scale=15, size=1000)\n",
        "\n",
        "print(\"Skewness:\", skew(data))\n",
        "print(\"Kurtosis:\", kurtosis(data))"
      ],
      "metadata": {
        "id": "M0pkH38Ollc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8. Generate a dataset and demonstrate positive and negative skewness"
      ],
      "metadata": {
        "id": "UGPU9meylu3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Positively skewed data\n",
        "pos_skewed = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Negatively skewed data\n",
        "neg_skewed = -np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "sns.histplot(pos_skewed, bins=30, kde=True, ax=axes[0])\n",
        "axes[0].set_title(\"Positive Skewness\")\n",
        "\n",
        "sns.histplot(neg_skewed, bins=30, kde=True, ax=axes[1])\n",
        "axes[1].set_title(\"Negative Skewness\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2_XdQ4fwlzv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9. Write a Python script to calculate covariance between two datasets"
      ],
      "metadata": {
        "id": "Lru7oNPkl2cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample datasets\n",
        "x = np.array([2, 4, 6, 8, 10])\n",
        "y = np.array([1, 3, 5, 7, 9])\n",
        "\n",
        "# Covariance\n",
        "cov_matrix = np.cov(x, y, bias=True)\n",
        "print(\"Covariance:\", cov_matrix[0, 1])"
      ],
      "metadata": {
        "id": "5TPLT0LLmA06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###10. Write a Python script to calculate the correlation coefficient between two datasets"
      ],
      "metadata": {
        "id": "YLFmf2yFmDla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample datasets\n",
        "x = np.array([2, 4, 6, 8, 10])\n",
        "y = np.array([1, 3, 5, 7, 9])\n",
        "\n",
        "# Pearson correlation coefficient\n",
        "correlation = np.corrcoef(x, y)[0, 1]\n",
        "print(\"Correlation Coefficient:\", correlation)"
      ],
      "metadata": {
        "id": "jcCVmo2WmdMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###11. Create a scatter plot to visualize the relationship between two variables python Copy Edit\n"
      ],
      "metadata": {
        "id": "HkF-LZXpoLmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data\n",
        "x = np.random.randint(10, 100, 50)\n",
        "y = x + np.random.normal(0, 10, 50)  # Adding noise\n",
        "\n",
        "plt.scatter(x, y, color='blue')\n",
        "plt.xlabel(\"X values\")\n",
        "plt.ylabel(\"Y values\")\n",
        "plt.title(\"Scatter Plot of Two Variables\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-n52pv8koWEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###12. Implement and compare simple random sampling and systematic sampling"
      ],
      "metadata": {
        "id": "8takafAHoi3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create dataset\n",
        "population = np.arange(1, 101)\n",
        "\n",
        "# Simple Random Sampling\n",
        "random_sample = np.random.choice(population, 10, replace=False)\n",
        "\n",
        "# Systematic Sampling (every k-th element)\n",
        "k = 10\n",
        "systematic_sample = population[::k]\n",
        "\n",
        "print(\"Random Sample:\", random_sample)\n",
        "print(\"Systematic Sample:\", systematic_sample)"
      ],
      "metadata": {
        "id": "m8ZcX9aEooRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###13. Calculate the mean, median, and mode of grouped data"
      ],
      "metadata": {
        "id": "zApsfjV2o2WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "# Grouped Data\n",
        "data = [10, 10, 20, 20, 20, 30, 40, 50, 50, 50, 50]\n",
        "\n",
        "mean = statistics.mean(data)\n",
        "median = statistics.median(data)\n",
        "mode = statistics.mode(data)\n",
        "\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Median:\", median)\n",
        "print(\"Mode:\", mode)"
      ],
      "metadata": {
        "id": "sb1vs0QZpAw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###14. Simulate data using Python and calculate its central tendency and dispersion"
      ],
      "metadata": {
        "id": "QRe1jarWpNC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Generate random data\n",
        "data = np.random.normal(loc=50, scale=10, size=1000)\n",
        "\n",
        "# Mean, Median, Mode\n",
        "mean = np.mean(data)\n",
        "median = np.median(data)\n",
        "mode = stats.mode(data)[0][0]\n",
        "\n",
        "# Dispersion\n",
        "variance = np.var(data, ddof=1)\n",
        "std_dev = np.std(data, ddof=1)\n",
        "range_value = np.ptp(data)\n",
        "\n",
        "print(f\"Mean: {mean}, Median: {median}, Mode: {mode}\")\n",
        "print(f\"Variance: {variance}, Standard Deviation: {std_dev}, Range: {range_value}\")"
      ],
      "metadata": {
        "id": "1rrFsdf7pOsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###15. Use NumPy or pandas to summarize a dataset’s descriptive statistics"
      ],
      "metadata": {
        "id": "hnfhkTzppRMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Generating a sample dataset\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'Age': np.random.randint(18, 60, 100),\n",
        "    'Height': np.random.normal(170, 10, 100),\n",
        "    'Weight': np.random.normal(70, 15, 100),\n",
        "    'Exam_Score': np.random.randint(40, 100, 100)\n",
        "})\n",
        "\n",
        "# Summary statistics\n",
        "print(data.describe())"
      ],
      "metadata": {
        "id": "alYB25SCqgr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###16. Plot a boxplot to understand the spread and identify outliers"
      ],
      "metadata": {
        "id": "kFugtMm5qoRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Creating boxplots\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=data)\n",
        "plt.title(\"Boxplot of Dataset Variables\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eZoYEm1_qr3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###17. Calculate the interquartile range (IQR) of a dataset."
      ],
      "metadata": {
        "id": "wLMF5F93qu8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = data.quantile(0.25)\n",
        "Q3 = data.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "print(\"Interquartile Range (IQR):\\n\", IQR)\n",
        "\n",
        "# Identifying outliers\n",
        "outliers = (data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))\n",
        "print(\"\\nOutliers in the dataset:\\n\", outliers.sum())  # Count of outliers per column"
      ],
      "metadata": {
        "id": "uoCXYFMAq8yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###18. Implement Z-score normalization and explain its significance."
      ],
      "metadata": {
        "id": "asPKBL75rSdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "data_zscore = data.apply(zscore)  # Apply Z-score normalization\n",
        "print(\"Z-score normalized dataset:\\n\", data_zscore.head())"
      ],
      "metadata": {
        "id": "6z7ZXyVzrdEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###19. Compare two datasets using their standard deviations."
      ],
      "metadata": {
        "id": "UOp6Q4kMryX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating another dataset\n",
        "data2 = pd.DataFrame({\n",
        "    'Age': np.random.randint(18, 60, 100),\n",
        "    'Height': np.random.normal(170, 20, 100),  # Larger SD\n",
        "    'Weight': np.random.normal(70, 25, 100),  # Larger SD\n",
        "    'Exam_Score': np.random.randint(40, 100, 100)\n",
        "})\n",
        "\n",
        "# Compute standard deviation\n",
        "std1 = data.std()\n",
        "std2 = data2.std()\n",
        "\n",
        "# Compare standard deviations\n",
        "comparison = pd.DataFrame({'Dataset 1': std1, 'Dataset 2': std2})\n",
        "print(\"\\nComparison of Standard Deviations:\\n\", comparison)"
      ],
      "metadata": {
        "id": "YJosx-qkr27n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###20. Write a Python program to visualize covariance using a heatmap."
      ],
      "metadata": {
        "id": "yKt6qFvmr564"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute covariance\n",
        "cov_matrix = data.cov()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cov_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Covariance Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HSpEJha6sUbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###21.  Use seaborn to create a correlation matrix for a dataset."
      ],
      "metadata": {
        "id": "3EIEiNH7sbVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute correlation matrix\n",
        "corr_matrix = data.corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6AS6EIFBsfyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###22. Generate a dataset and implement both variance and standard deviation computations."
      ],
      "metadata": {
        "id": "0FcXccJqsmMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Generate a random dataset\n",
        "np.random.seed(42)  # For reproducibility\n",
        "data = pd.DataFrame({\n",
        "    'Age': np.random.randint(18, 60, 100),  # Random ages between 18 and 60\n",
        "    'Height': np.random.normal(170, 10, 100),  # Normally distributed heights (mean=170, std=10)\n",
        "    'Weight': np.random.normal(70, 15, 100),  # Normally distributed weights (mean=70, std=15)\n",
        "    'Exam_Score': np.random.randint(40, 100, 100)  # Random scores between 40 and 100\n",
        "})\n",
        "\n",
        "# Step 2: Compute variance and standard deviation using NumPy\n",
        "variance_np = np.var(data, axis=0, ddof=1)  # ddof=1 for sample variance\n",
        "std_dev_np = np.std(data, axis=0, ddof=1)\n",
        "\n",
        "# Step 3: Compute variance and standard deviation using pandas\n",
        "variance_pd = data.var()\n",
        "std_dev_pd = data.std()\n",
        "\n",
        "# Display results\n",
        "print(\"📌 Variance using NumPy:\\n\", variance_np)\n",
        "print(\"\\n📌 Standard Deviation using NumPy:\\n\", std_dev_np)\n",
        "\n",
        "print(\"\\n📌 Variance using pandas:\\n\", variance_pd)\n",
        "print(\"\\n📌 Standard Deviation using pandas:\\n\", std_dev_pd)"
      ],
      "metadata": {
        "id": "ns64Sxf8st5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###23. Visualize skewness and kurtosis using Python libraries like matplotlib or seaborn."
      ],
      "metadata": {
        "id": "UMPRcf58tDCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Step 1: Generate a random dataset with different distributions\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'Normal_Distribution': np.random.normal(50, 15, 1000),  # Mean=50, Std=15\n",
        "    'Positively_Skewed': np.random.exponential(10, 1000),  # Exponential (Right skewed)\n",
        "    'Negatively_Skewed': 100 - np.random.exponential(10, 1000)  # Left skewed\n",
        "})\n",
        "\n",
        "# Step 2: Compute skewness and kurtosis\n",
        "skewness_values = data.apply(skew)\n",
        "kurtosis_values = data.apply(kurtosis)\n",
        "\n",
        "print(\"📌 Skewness:\\n\", skewness_values)\n",
        "print(\"\\n📌 Kurtosis:\\n\", kurtosis_values)\n",
        "\n",
        "# Step 3: Plot histograms & KDE for visualization\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for i, col in enumerate(data.columns):\n",
        "    sns.histplot(data[col], kde=True, bins=30, ax=axes[i])\n",
        "    axes[i].set_title(f'{col}\\nSkewness: {skewness_values[col]:.2f} | Kurtosis: {kurtosis_values[col]:.2f}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0K5_8UcstYgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###24. Implement the Pearson and Spearman correlation coefficients for a dataset."
      ],
      "metadata": {
        "id": "PvkuVCY9txAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Step 1: Generate a synthetic dataset\n",
        "np.random.seed(42)\n",
        "size = 100\n",
        "\n",
        "# Creating two correlated variables\n",
        "x = np.random.normal(50, 15, size)\n",
        "y = 2 * x + np.random.normal(0, 10, size)  # Strong positive linear correlation\n",
        "y_non_linear = np.exp(x / 50) + np.random.normal(0, 0.5, size)  # Non-linear relationship\n",
        "\n",
        "# Creating a DataFrame\n",
        "data = pd.DataFrame({'X': x, 'Y_Linear': y, 'Y_NonLinear': y_non_linear})\n",
        "\n",
        "# Step 2: Compute Pearson & Spearman Correlation\n",
        "pearson_corr, _ = pearsonr(data['X'], data['Y_Linear'])\n",
        "spearman_corr, _ = spearmanr(data['X'], data['Y_NonLinear'])\n",
        "\n",
        "print(f\"📌 Pearson Correlation (Linear Relationship): {pearson_corr:.4f}\")\n",
        "print(f\"📌 Spearman Correlation (Non-Linear Relationship): {spearman_corr:.4f}\")\n",
        "\n",
        "# Step 3: Visualizing Correlations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Scatter plot for Pearson Correlation (Linear)\n",
        "sns.scatterplot(x=data['X'], y=data['Y_Linear'], ax=axes[0])\n",
        "axes[0].set_title(f'Linear Relationship\\nPearson Correlation: {pearson_corr:.2f}')\n",
        "\n",
        "# Scatter plot for Spearman Correlation (Non-Linear)\n",
        "sns.scatterplot(x=data['X'], y=data['Y_NonLinear'], ax=axes[1])\n",
        "axes[1].set_title(f'Non-Linear Relationship\\nSpearman Correlation: {spearman_corr:.2f}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HclskgRBt7wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "#Thank you!\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "7C4dlTjxuKqz"
      }
    }
  ]
}